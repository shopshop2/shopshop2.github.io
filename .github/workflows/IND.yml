name: 'IND'
on:
  schedule:
    - cron: '25 19 * * *'
  workflow_dispatch:
jobs:
  submit-urls:
    runs-on: ubuntu-latest
    permissions:
      contents: read
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Get modified files
        run: |
          # 모든 변경 사항 가져오기
          git fetch --all --prune
          git pull --all
          
          # 24시간 이내의 커밋들에서 변경된 파일 찾기
          CHANGED_FILES=$(git log --since="24 hours ago" --name-only --pretty="" | grep -E "^_posts/.*\.md$" | sort -u || true)
          
          echo "Files changed in last 24 hours:"
          echo "$CHANGED_FILES"
          
          # 파일 수정 시간 확인
          RESULT=""
          while IFS= read -r file; do
            if [ ! -z "$file" ] && [ -f "$file" ]; then
              STAT=$(git log -1 --format="%ct" -- "$file")
              NOW=$(date +%s)
              DIFF=$((NOW - STAT))
              echo "File: $file (modified $((DIFF / 3600)) hours ago)"
              if [ $DIFF -le 86400 ]; then
                RESULT="${RESULT}${file}"$'\n'
                echo "-> Added to processing list"
              fi
            fi
          done <<< "$CHANGED_FILES"
          
          CHANGED_FILES="$RESULT"
          echo -e "\nFinal list of files to process:"
          echo "$CHANGED_FILES"
          
          if [ ! -z "$CHANGED_FILES" ]; then
            python3 -c 'import os,json,urllib.parse,sys; def decode_url_path(path): return urllib.parse.unquote(path)[len("_posts/"):].split(".md")[0][11:] if urllib.parse.unquote(path).startswith("_posts/") and urllib.parse.unquote(path).startswith("2024-03-") else path; changed_files=os.environ.get("CHANGED_FILES","").splitlines(); url_list=[f"https://shopshop2.github.io/shopping/{"-".join(filter(None, decode_url_path(file).split("-")))}/" for file in changed_files if file.strip()]; [print(f"Processing: {url}") for url in url_list]; data={"host":"shopshop2.github.io","key":"87ae650ca3ec4b2daec3bee8fa7ac2e3","urlList":url_list,"keyLocation":"https://shopshop2.github.io/87ae650ca3ec4b2daec3bee8fa7ac2e3.txt"} if url_list else None; json.dump(data, open("/tmp/indexnow_data.json", "w", encoding="utf-8"), ensure_ascii=False, indent=2) if data else (print("No valid URLs found to process") or sys.exit(1))'

            if [ -f "/tmp/indexnow_data.json" ]; then
              response=$(curl -s -w "\nHTTP Status: %{http_code}" -X POST "https://api.indexnow.org/indexnow" \
                -H "Content-Type: application/json" \
                -d @/tmp/indexnow_data.json)
              
              echo "IndexNow API Response:"
              echo "$response"
              
              if echo "$response" | grep -q "HTTP Status: 200"; then
                echo "URLs successfully submitted to search engines!"
              else
                echo "Error submitting URLs. Please check the response above."
                exit 1
              fi
            fi
          else
            echo "No markdown files found in _posts directory in the last 24 hours"
            exit 0
          fi
        env:
          CHANGED_FILES: "$CHANGED_FILES"
