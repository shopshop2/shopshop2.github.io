name: 'IND'
on:
  schedule:
    - cron: '25 19 * * *'  # UTC 19:25 = KST 04:25
  workflow_dispatch:
jobs:
  submit-urls:
    runs-on: ubuntu-latest
    permissions:
      contents: read
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: Install Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'
          
      - name: Get modified files
        env:
          CHANGED_FILES: ""
        run: |
          echo "Finding files modified in the last 24 hours..."
          # 24시간 내의 커밋에서 수정된 파일만 찾기
          CHANGED_FILES=$(git log --since="24 hours ago" --format="" --name-only | grep "^_posts/.*\.md$" | sort -u)
          echo "Modified files in the last 24 hours:"
          echo "$CHANGED_FILES"
          
          if [ ! -z "$CHANGED_FILES" ]; then
            python3 << 'EOL'
          import os
          import json
          import urllib.parse
          import sys

          def decode_url_path(path):
              try:
                  decoded = urllib.parse.unquote(path)
                  if decoded.startswith('_posts/'):
                      decoded = decoded[len('_posts/'):].split('.md')[0]
                  if decoded.startswith('2024-03-'):
                      decoded = decoded[11:]
                  return decoded
              except Exception as e:
                  print(f"Error decoding path: {e}", file=sys.stderr)
                  return path

          changed_files = os.environ.get('CHANGED_FILES', '').splitlines()
          url_list = []
          seen_urls = set()

          for file in changed_files:
              if file.strip():
                  decoded_path = decode_url_path(file)
                  cleaned_path = '-'.join(filter(None, decoded_path.split('-')))
                  url = f"https://shopshop2.github.io/shopping/{cleaned_path}/"
                  if url not in seen_urls:
                      seen_urls.add(url)
                      url_list.append(url)
                      print(f"Processing: {url}")

          if url_list:
              data = {
                  "host": "shopshop2.github.io",
                  "key": "87ae650ca3ec4b2daec3bee8fa7ac2e3",
                  "urlList": url_list,
                  "keyLocation": "https://shopshop2.github.io/87ae650ca3ec4b2daec3bee8fa7ac2e3.txt"
              }
              with open('/tmp/indexnow_data.json', 'w', encoding='utf-8') as f:
                  json.dump(data, f, ensure_ascii=False, indent=2)
              print("URL List prepared successfully")
          else:
              print("No valid URLs found to process")
              sys.exit(1)
          EOL

            if [ -f "/tmp/indexnow_data.json" ]; then
              response=$(curl -s -w "\nHTTP Status: %{http_code}" -X POST "https://api.indexnow.org/indexnow" \
                -H "Content-Type: application/json" \
                -d @/tmp/indexnow_data.json)
              
              echo "IndexNow API Response:"
              echo "$response"
              
              if echo "$response" | grep -q "HTTP Status: 200"; then
                echo "URLs successfully submitted to search engines!"
              else
                echo "Error submitting URLs. Please check the response above."
                exit 1
              fi
            fi
          else
            echo "No markdown files found in _posts directory in the last 24 hours"
            exit 0
          fi
